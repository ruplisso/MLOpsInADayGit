{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Azure Machine Learning Pipeline (Student)\r\n",
        "\r\n",
        " In this notebook, we will be creating a Azure Machine Learning Pipeline for the complete stage of machine learning lifecycle:\r\n",
        " \r\n",
        " 1. Data Engineering\r\n",
        " 2. Model Training\r\n",
        " 3. Model Management\r\n",
        " 4. Model Deployment (to same environment)\r\n",
        " \r\n",
        "![Data Engineering](./images/00-Pipeline.jpg)\r\n",
        "\r\n",
        "\r\n",
        "Fill in the blanks and make the notebook work. This notebook might also has bugs needed to be fixed. The expected result is a scheduled published pipeline."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Engineering \r\n",
        "\r\n",
        "**Input** : Raw Data \r\n",
        "\r\n",
        "**Output** : Registered Data Set (ProductReview)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "os.makedirs('data_engineering',exist_ok=True)\r\n",
        "os.makedirs('train', exist_ok=True)\r\n",
        "os.makedirs('model_selection', exist_ok=True)\r\n",
        "os.makedirs('model_deploy', exist_ok=True)\r\n"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646249345814
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile data_engineering/data_engineering.py\r\n",
        "import os\r\n",
        "import json\r\n",
        "import gzip\r\n",
        "import pandas as pd\r\n",
        "from urllib.request import urlopen\r\n",
        "import requests\r\n",
        "\r\n",
        "from azureml.core.run import Run\r\n",
        "from azureml.core import Dataset, Datastore, Workspace\r\n",
        "from azureml.data.datapath import DataPath\r\n",
        "\r\n",
        "# get run context\r\n",
        "run = Run._____________________\r\n",
        "\r\n",
        "# Download data from source\r\n",
        "url = \"http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Software_5.json.gz\"\r\n",
        "response = requests.get(url, stream=True)\r\n",
        "\r\n",
        "with open(\"Software_5.json.gz\", \"wb\") as handle:\r\n",
        "    for data in response.iter_content():\r\n",
        "        handle.write(data)\r\n",
        "\r\n",
        "### load the meta data\r\n",
        "data = []\r\n",
        "with gzip.open('Software_5.json.gz') as f:\r\n",
        "    for l in f:\r\n",
        "        data.append(json.loads(l.strip()))\r\n",
        "    \r\n",
        "# total length of list, this number equals total number of products\r\n",
        "print(len(data))\r\n",
        "\r\n",
        "# first row of the list\r\n",
        "print(data[0])\r\n",
        "df = pd.DataFrame.from_dict(data)\r\n",
        "\r\n",
        "### remove rows with unformatted title (i.e. some 'title' may still contain html style content)\r\n",
        "df3 = df.fillna('')\r\n",
        "df3.iloc[2]\r\n",
        "\r\n",
        "# Prepare dataset\r\n",
        "workspace = _____________________\r\n",
        "default_datastore = Datastore.get_default(workspace)\r\n",
        "\r\n",
        "ds_name = 'ProductReview'\r\n",
        "data_path = DataPath(datastore=default_datastore, path_on_datastore='product_review')\r\n",
        "\r\n",
        "# Register dataset \r\n",
        "# Hint: register_xxxxx\r\n",
        "ds = Dataset.Tabular.__________________(___, \r\n",
        "                                    ____________, \r\n",
        "                                    ____________, \r\n",
        "                                    description=None, \r\n",
        "                                    tags=None, \r\n",
        "                                    show_progress=True)\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting dataengineer/data_engineer.py\n"
        }
      ],
      "execution_count": 51,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1638856840545
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Training\r\n",
        "\r\n",
        "Use existing train_2.py from previous demo."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train/train_2.py\r\n",
        "# General libraries.\r\n",
        "import numpy as np\r\n",
        "from sklearn.naive_bayes import MultinomialNB\r\n",
        "from sklearn import metrics\r\n",
        "from sklearn.metrics import classification_report,plot_confusion_matrix, ConfusionMatrixDisplay\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from azureml.core.run import Run\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "from azureml.core import Workspace, Dataset\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from joblib import dump\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "\r\n",
        "run = ________________\r\n",
        "\r\n",
        "# Get workspace from run context\r\n",
        "workspace = __________________________\r\n",
        "\r\n",
        "# Load Data\r\n",
        "dataset = Dataset.get_by_name(workspace, name='ProductReview')\r\n",
        "data = dataset.to_pandas_dataframe()[['overall', 'reviewText']]\r\n",
        "\r\n",
        "# Prepare X & Y\r\n",
        "Y = data.pop('overall').to_numpy()\r\n",
        "X = data.pop('reviewText').to_numpy()\r\n",
        "train_x, test_x, train_y, test_y = train_test_split(X,Y, test_size = 0.1, random_state=1)\r\n",
        "\r\n",
        "\r\n",
        "vec = CountVectorizer()\r\n",
        "fitted_train_data = vec.fit_transform(train_x)\r\n",
        "fitted_test_data = vec.transform(test_x)\r\n",
        "\r\n",
        "model = MultinomialNB()\r\n",
        "params = {'alpha': [1.0e-5, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0]}\r\n",
        "\r\n",
        "clf = GridSearchCV(model, params, scoring = \"f1_macro\", verbose=0, cv = 5)\r\n",
        "clf_result = clf.fit(fitted_train_data, train_y)\r\n",
        "run.___(\"Best alpha \",clf_result.best_estimator_.alpha)\r\n",
        "pred = clf.predict(fitted_test_data)\r\n",
        "run.___(\"F1\", metrics.f1_score(test_y, pred, average='weighted'))\r\n",
        "\r\n",
        "plot_confusion_matrix(clf, fitted_test_data, test_y)  \r\n",
        "plt.savefig('confusion_matrix.png')\r\n",
        "# Record image to run\r\n",
        "run.__________________(name='Confusion-Matrix', path='./confusion_matrix.png')\r\n",
        "\r\n",
        "# Save trained model\r\n",
        "dump(vec, './vec.pkl')\r\n",
        "dump(clf, './mnb.pkl')\r\n",
        "run.____________(name='vec.pkl', path_or_stream=___________)\r\n",
        "run.____________(name='mnb.pkl', path_or_stream=___________)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Selection\r\n",
        "\r\n",
        "In this step, we will use a predefined metrics **F1**. We will list all today's runs and select the highest F1 score model, which will be registered in Model Registry and prepare for deployment."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model_selection/model_select.py\r\n",
        "import sklearn\r\n",
        "from datetime import datetime, date\r\n",
        "from azureml.core.run import Run\r\n",
        "# from azureml.core import Experiment\r\n",
        "# from azureml.core.model import Model\r\n",
        "\r\n",
        "# get run context\r\n",
        "run = Run.get_context()\r\n",
        "workspace = run.experiment.workspace\r\n",
        "\r\n",
        "# Get Experiment and runs for model select\r\n",
        "# In this step, we will use F1\r\n",
        "exp = run.__________ # Experiment.list(workspace, experiment_name='MLOps-Workshop')\r\n",
        "\r\n",
        "today = date.today()\r\n",
        "\r\n",
        "select_run = None\r\n",
        "F1 = 0\r\n",
        "for r in exp.get_runs():\r\n",
        "    run_starttime = datetime.strptime(r.______________['startTimeUtc'][:10], '%Y-%m-%d').date()\r\n",
        "    if run_starttime==today:\r\n",
        "        for step in r.get_children():\r\n",
        "            current_step_f1 = step.__________(name='F1') # Get F1 metrics\r\n",
        "            if 'F1' in current_step_f1.keys() and F1<current_step_f1['F1']:\r\n",
        "                F1=current_step_f1['F1']\r\n",
        "                select_run = step\r\n",
        "    \r\n",
        "if select_run != None:\r\n",
        "    # Load Data\r\n",
        "    mnb_model = select_run.register_model(\"ProductReview-NaiveBayes\",\r\n",
        "                            model_path=\"./mnb.pkl\",\r\n",
        "                            )\r\n",
        "\r\n",
        "    vector    = select_run.register_model(\"ProductReview-CountVector\", \r\n",
        "                            model_path=\"./vec.pkl\",\r\n",
        "                            )"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting model_selection/model_select.py\n"
        }
      ],
      "execution_count": 109,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare for Model Package"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model_deploy/score.py\r\n",
        "import json, os, joblib\r\n",
        "from azureml.core.model import _____\r\n",
        "\r\n",
        "def init(): \r\n",
        "  global vec, clf\r\n",
        "  print(Model.get_model_path('ProductReview-NaiveBayes'))\r\n",
        "  vec = joblib.load(Model.get_model_path('ProductReview-CountVector'))\r\n",
        "  clf = joblib.load(Model.get_model_path('ProductReview-NaiveBayes'))\r\n",
        "\r\n",
        "def run(data): \r\n",
        "  input_data = json.loads(data)['data'] \r\n",
        "  fitted_data = vec.transform(input_data)\r\n",
        "  pred = clf.predict(fitted_data)\r\n",
        "  return json.dumps(pred.tolist())\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Writing model_deploy/score.py\n"
        }
      ],
      "execution_count": 112,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model_deploy/deploy.py\r\n",
        "from azureml.core.model import InferenceConfig, Model\r\n",
        "from azureml.core import Environment\r\n",
        "from azureml.core.run import Run\r\n",
        "from azureml.core.webservice import AciWebservice\r\n",
        "\r\n",
        "# get run context\r\n",
        "run = Run.get_context()\r\n",
        "workspace = run.experiment.workspace\r\n",
        "\r\n",
        "service_name = 'product-review-service'\r\n",
        "env = Environment.get(workspace=workspace, name=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu\")\r\n",
        "\r\n",
        "inference_config = InferenceConfig(entry_script=________, \r\n",
        "                            source_directory=_______,\r\n",
        "                            environment=________)\r\n",
        "\r\n",
        "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\r\n",
        "\r\n",
        "nb_model = Model(workspace, 'ProductReview-NaiveBayes')\r\n",
        "vectorizor = Model(workspace, 'ProductReview-CountVector')\r\n",
        "\r\n",
        "service = Model.deploy(\r\n",
        "    _________,\r\n",
        "    name = ___________,\r\n",
        "    models=[nb_model, vectorizor],\r\n",
        "    inference_config= _________,\r\n",
        "    deployment_config= ____________,\r\n",
        "    overwrite=True,\r\n",
        ")\r\n",
        "service.wait_for_deployment(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting model_deploy/deploy.py\n"
        }
      ],
      "execution_count": 117,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.steps import PythonScriptStep\r\n",
        "from azureml.pipeline.core import Pipeline, PipelineData\r\n",
        "import azureml.core\r\n",
        "from azureml.core import Workspace, Environment, Experiment\r\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\r\n",
        "from azureml.core.compute_target import ComputeTargetException\r\n",
        "from azureml.core.runconfig import RunConfiguration\r\n",
        "import os\r\n",
        "\r\n",
        "workspace=Workspace.from_config()\r\n",
        "# Get ComputeTarget\r\n",
        "aml_compute_target = \"cpu-cluster\"\r\n",
        "try:\r\n",
        "    aml_compute = AmlCompute(workspace, aml_compute_target)\r\n",
        "    print(\"found existing compute target.\")\r\n",
        "except ComputeTargetException:\r\n",
        "    print(\"creating new compute target\")\r\n",
        "    \r\n",
        "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_D2_V2\",\r\n",
        "                                                                min_nodes = 0, \r\n",
        "                                                                max_nodes = 4)    \r\n",
        "    aml_compute = ComputeTarget.create(workspace, aml_compute_target, provisioning_config)\r\n",
        "    aml_compute.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\r\n",
        "    \r\n",
        "print(\"Azure Machine Learning Compute attached\")\r\n",
        "\r\n",
        "env = Environment.___(workspace=workspace, name=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu\")\r\n",
        "# create a new runconfig object\r\n",
        "runconfig = RunConfiguration()\r\n",
        "runconfig.environment = env\r\n",
        "\r\n",
        "dataprep_step = PythonScriptStep( name=\"prep_data\", \r\n",
        "                                script_name=________________, \r\n",
        "\t                            source_directory=\"data_engineering\", \r\n",
        "                                compute_target=_________________, \r\n",
        "                                runconfig=runconfig                                \r\n",
        "\t                            )\r\n",
        "\r\n",
        "train_step    = PythonScriptStep( name=\"train\", \r\n",
        "                                script_name=__________, \r\n",
        "\t                            source_directory=\"train\", \r\n",
        "                                compute_target=_________________, \r\n",
        "                                runconfig=runconfig\r\n",
        "\t                            )\r\n",
        "train_step.run_after(dataprep_step)\r\n",
        "\r\n",
        "select_step   = PythonScriptStep( name=\"select_model\", \r\n",
        "                                script_name=__________, \r\n",
        "\t                            source_directory=\"model_selection\", \r\n",
        "                                compute_target=_________________, \r\n",
        "                                runconfig=runconfig\r\n",
        "\t                            )\r\n",
        "select_step.run_after(train_step)\r\n",
        "\r\n",
        "deploy_step   = PythonScriptStep( name=\"deploy_model\", \r\n",
        "                                script_name=__________, \r\n",
        "\t                            source_directory=\"model_deploy\", \r\n",
        "                                compute_target=____________________, \r\n",
        "                                runconfig=runconfig\r\n",
        "\t                            )\r\n",
        "deploy_step.run_after(select_step)\r\n",
        "\r\n",
        "experiment_name = 'MLOps-Workshop'\r\n",
        "pipeline = Pipeline(workspace=workspace, steps=[_____________])\r\n",
        "pipeline_run = Experiment(workspace, experiment_name).submit(_________)\r\n",
        "print(\"Pipeline is submitted for execution\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "found existing compute target.\nAzure Machine Learning Compute attached\nCreated step deploy_model [f4398fe2][ef707c3f-6ebe-49bd-875b-abd38b13068b], (This step is eligible to reuse a previous run's output)\nCreated step select_model [e3cf3603][ba6b0607-caaf-42f4-800d-f11a41cd11fb], (This step is eligible to reuse a previous run's output)Created step train [fca8188c][9a901d98-bd6d-432f-b4de-1dfae832f1be], (This step is eligible to reuse a previous run's output)\n\nCreated step prep_data [215c71e8][353e7ebf-5a4e-4138-8093-a54b5c71bf41], (This step is eligible to reuse a previous run's output)\nSubmitted PipelineRun 33581c8a-011b-4ba9-8a64-2beb3c97f9fe\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/33581c8a-011b-4ba9-8a64-2beb3c97f9fe?wsid=/subscriptions/f3f672c1-6cfc-4f72-92ae-2b1ab1c0cf69/resourcegroups/mlrg/workspaces/mymlspace&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\nPipeline is submitted for execution\n"
        }
      ],
      "execution_count": 118,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1638939588467
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Endpoint"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests, json\r\n",
        "\r\n",
        "# replace uri below with your service endpoint\r\n",
        "uri = 'http://71ed97f8-aa0f-4c14-871f-b7c9687e8443.westus2.azurecontainer.io/score'\r\n",
        "\r\n",
        "headers = {\"Content-Type\": \"application/json\"}\r\n",
        "comments = \"\"\"\r\n",
        "\"I've been using Dreamweaver (and it's predecessor Macromedia's UltraDev) for many years.  \r\n",
        "For someone who is an experienced web designer, this course is a high-level review of the CS5 version of Dreamweaver,\r\n",
        " but it doesn't go into a great enough level of detail to find it very useful.\\n\\nOn the other hand, \r\n",
        " this is a great tool for someone who is a relative novice at web design.  \r\n",
        " It starts off with a basic overview of HTML and continues through the concepts necessary to build a modern web site.  \r\n",
        " Someone who goes through this course should exit with enough knowledge to create something that does what \r\n",
        " you want it do do...within reason.  Don't expect to go off and build an entire e-commerce system with only this class \r\n",
        " under your belt.\\n\\nIt's important to note that there's a long gap from site design to actual implementation.  \r\n",
        " This course teaches you how to implement a design.  The user interface and overall user experience is a different \r\n",
        " subject that isn't covered here...it's possible to do a great implementation of an absolutely abysmal design.  \r\n",
        " I speak from experience.  :)\\n\\nAs I said above, if you're a novice, a relative newcomer or just an experienced web \r\n",
        " designer who wants a refresher course, this is a good way to do it.\"\r\n",
        "\"\"\"\r\n",
        "sample_input = json.dumps({\r\n",
        "    'data': [comments]\r\n",
        "})\r\n",
        "response = requests.post(uri, data=sample_input, headers=headers)\r\n",
        "print(response.json())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[4.0]\n"
        }
      ],
      "execution_count": 119,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1638939822169
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Publish Pipeline"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "published_pipeline = pipeline_run._____________(\r\n",
        "     name=\"MLOps-Workshop-Pipeline\",\r\n",
        "     description=\"Published Pipeline for MLOps Workshop\",\r\n",
        "     version=\"1.0\")"
      ],
      "outputs": [],
      "execution_count": 138,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1638941007044
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "published_pipeline.id"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 139,
          "data": {
            "text/plain": "'7cd1356f-dc16-4df6-be0d-622e3da5ba63'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 139,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1638941014091
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Schedule Pipeline runs\r\n",
        "\r\n",
        "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-trigger-published-pipeline\r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core.schedule import ScheduleRecurrence, Schedule\r\n",
        "\r\n",
        "## create time-based pipeline\r\n",
        "# Frequency can be Minute / Hour / Day / Week / Month\r\n",
        "recurrence = ScheduleRecurrence(frequency=\"Month\", interval=1)\r\n",
        "recurring_schedule = Schedule.create(workspace, name=\"MonthlySchedule\", \r\n",
        "                            description=\"Based on time\",\r\n",
        "                            pipeline_id=published_pipeline.id, \r\n",
        "                            experiment_name=experiment_name, \r\n",
        "                            recurrence=recurrence)"
      ],
      "outputs": [],
      "execution_count": 140,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1638941024911
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "recurring_schedule\r\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 141,
          "data": {
            "text/plain": "Pipeline(Name: MonthlySchedule,\nId: af9d2e20-1cf5-441b-ac90-ca7ea750f95a,\nStatus: Active,\nPipeline Id: 7cd1356f-dc16-4df6-be0d-622e3da5ba63,\nPipeline Endpoint Id: None,\nRecurrence Details: Runs every Month)",
            "text/html": "<table style=\"width:100%\"><tr><th>Name</th><th>Id</th><th>Status</th><th>Pipeline Id</th><th>Pipeline Endpoint Id</th><th>Recurrence Details</th></tr><tr><td>MonthlySchedule</td><td>af9d2e20-1cf5-441b-ac90-ca7ea750f95a</td><td>Active</td><td><a href=\"https://ml.azure.com/pipelines/7cd1356f-dc16-4df6-be0d-622e3da5ba63?wsid=/subscriptions/f3f672c1-6cfc-4f72-92ae-2b1ab1c0cf69/resourcegroups/mlrg/workspaces/mymlspace\" target=\"_blank\" rel=\"noopener\">7cd1356f-dc16-4df6-be0d-622e3da5ba63</a></td><td></td><td>Runs every Month</td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 141,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1638941036996
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pipeline Schedule Management\r\n",
        "\r\n",
        "- Enable / Disable\r\n",
        "\r\n",
        "enable(wait_for_provisioning=False, wait_timeout=3600)\r\n",
        "\r\n",
        "disable(wait_for_provisioning=False, wait_timeout=3600)\r\n",
        "\r\n",
        "- Get (Set the schedule to 'Active' and available to run)\r\n",
        "\r\n",
        "get(workspace, id, _workflow_provider=None, _service_endpoint=None)\r\n",
        "\r\n",
        "- List ( Get all schedules in the current workspace)\r\n",
        "\r\n",
        "list(workspace, active_only=True, pipeline_id=None, pipeline_endpoint_id=None, _workflow_provider=None, _service_endpoint=None)\r\n",
        "\r\n",
        "\r\n",
        "https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/machine-learning-pipelines/intro-to-pipelines/aml-pipelines-setup-schedule-for-a-published-pipeline.ipynb\r\n",
        "\r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}